import json
import mlflow
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from elasticsearch import Elasticsearch
import joblib
import numpy as np
from model_pipeline import prepare_data, train_model, save_model, load_model  # Assurez-vous que les imports sont utilis√©s.

# Connexion √† Elasticsearch
es = Elasticsearch(["http://localhost:9200"])

if es.ping():
    print("‚úÖ Connexion Elasticsearch r√©ussie !")
else:
    print("‚ùå Impossible de se connecter √† Elasticsearch !")

def log_to_elasticsearch(experiment_id, run_id, metrics):
    """Envoie les logs de MLflow √† Elasticsearch pour stockage."""
    log_entry = {"experiment_id": experiment_id, "run_id": run_id, "metrics": metrics}

    try:
        response = es.index(index="mlflow-metrics", body=json.dumps(log_entry))
        print(f"‚úÖ Log envoy√© √† Elasticsearch : {response}")
    except Exception as e:
        print(f"‚ùå Erreur lors de l'envoi des logs √† Elasticsearch : {str(e)}")

# D√©finir le tracking URI MLflow
mlflow.set_tracking_uri("http://localhost:5005")
print(f"üîç MLflow Tracking URI utilis√© : {mlflow.get_tracking_uri()}")

# D√©finition des chemins des fichiers et mod√®les
MODEL_PATH = "model.pkl"
TRAIN_FILE_PATH = "churn-bigml-80.csv"
TEST_FILE_PATH = "churn-bigml-20.csv"

# Initialisation de l'API FastAPI
app = FastAPI()

# Charger le mod√®le au d√©marrage de l'API
try:
    current_model = joblib.load(MODEL_PATH)
    print("‚úÖ Mod√®le charg√© avec succ√®s !")
except Exception as e:
    print(f"‚ùå Erreur lors du chargement du mod√®le : {e}")
    current_model = None

# Format des donn√©es d'entr√©e pour la pr√©diction
class ChurnInput(BaseModel):
    features: list

class RetrainParams(BaseModel):
    n_estimators: int = 100
    max_depth: int = None
    min_samples_split: int = 2
    min_samples_leaf: int = 1

@app.get("/")
def home():
    """Endpoint pour tester si l'API fonctionne."""
    return {"message": "L'API FastAPI fonctionne !"}

@app.post("/predict")
def predict(data: ChurnInput):
    """Endpoint pour faire des pr√©dictions avec le mod√®le."""
    try:
        print(f"üì® Donn√©es re√ßues : {data.features}")

        if current_model is None:
            raise HTTPException(status_code=500, detail="Mod√®le non charg√©. Essayez de le r√©entra√Æner.")

        input_data = np.array(data.features).reshape(1, -1)
        prediction = current_model.predict(input_data)

        print(f"‚úÖ Pr√©diction faite : {prediction[0]}")
        return {"prediction": int(prediction[0])}

    except Exception as e:
        print(f"‚ùå Erreur de pr√©diction : {e}")
        raise HTTPException(status_code=400, detail=f"Erreur de pr√©diction : {str(e)}")

@app.post("/retrain_params")
def retrain_params(params: RetrainParams):
    """Endpoint pour r√©entra√Æner le mod√®le avec des hyperparam√®tres personnalis√©s."""
    try:
        print("üîÑ D√©but du r√©entra√Ænement du mod√®le avec hyperparam√®tres...")

        X_train, X_test, y_train, y_test = prepare_data(TRAIN_FILE_PATH, TEST_FILE_PATH)

        new_model = train_model(
            X_train,
            y_train,
            n_estimators=params.n_estimators,
            max_depth=params.max_depth,
            min_samples_split=params.min_samples_split,
            min_samples_leaf=params.min_samples_leaf,
        )

        save_model(new_model, MODEL_PATH)

        current_model = new_model

        with mlflow.start_run() as run:
            mlflow.log_params(params.dict())
            mlflow.log_metric("accuracy", 0.95)  # Remplace avec l'accuracy r√©elle

            log_to_elasticsearch(
                experiment_id=mlflow.active_run().info.experiment_id,
                run_id=mlflow.active_run().info.run_id,
                metrics={"accuracy": 0.95},  # Remplace avec l'accuracy r√©elle
            )

        print("‚úÖ Mod√®le r√©entra√Æn√© avec succ√®s avec les nouveaux hyperparam√®tres !")
        return {"message": "Mod√®le r√©entra√Æn√© avec succ√®s.", "params": params.dict()}

    except Exception as e:
        print(f"‚ùå Erreur lors du r√©entra√Ænement : {e}")
        raise HTTPException(status_code=500, detail=f"Erreur : {str(e)}")

@app.post("/retrain")
def retrain():
    """Endpoint pour r√©entra√Æner le mod√®le avec les hyperparam√®tres par d√©faut."""
    try:
        print("üîÑ D√©but du r√©entra√Ænement du mod√®le avec les param√®tres par d√©faut...")

        X_train, X_test, y_train, y_test = prepare_data(TRAIN_FILE_PATH, TEST_FILE_PATH)

        new_model = train_model(
            X_train,
            y_train,
            n_estimators=100,
            max_depth=None,
            min_samples_split=2,
            min_samples_leaf=1,
        )

        save_model(new_model, MODEL_PATH)

        current_model = new_model

        with mlflow.start_run() as run:
            mlflow.log_metric("accuracy", 0.95)  # Remplace avec la vraie accuracy
            log_to_elasticsearch(
                experiment_id=mlflow.active_run().info.experiment_id,
                run_id=mlflow.active_run().info.run_id,
                metrics={"accuracy": 0.95},  # Remplace avec la vraie accuracy
            )

        print("‚úÖ Mod√®le r√©entra√Æn√© avec succ√®s avec les param√®tres par d√©faut !")
        return {"message": "Mod√®le r√©entra√Æn√© avec succ√®s avec les param√®tres par d√©faut."}

    except Exception as e:
        print(f"‚ùå Erreur lors du r√©entra√Ænement : {e}")
        raise HTTPException(status_code=500, detail=f"Erreur : {str(e)}")

# D√©marrer l'API FastAPI
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8001, reload=True)

